{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import os\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "\n",
    "import dotenv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import polars as pl\n",
    "import random_name\n",
    "import sklearn\n",
    "import torch\n",
    "from bertopic import BERTopic\n",
    "from hdbscan import HDBSCAN\n",
    "from more_itertools import chunked\n",
    "from sklearn.cluster import KMeans\n",
    "from umap import UMAP\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "from typing import Union, List, Iterable\n",
    "from catalyst import metrics\n",
    "\n",
    "from vdorogu.inferencer.inference import Inferencer\n",
    "from vdorogu.modeling.module import M1Model\n",
    "\n",
    "if sklearn.__version__ < \"1.2.2\":\n",
    "    from sklearn.feature_extraction import CountVectorizer\n",
    "else:\n",
    "    from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Monitor:\n",
    "        def __init__(self, classes):\n",
    "            self.monitor = {key: metrics.AdditiveMetric(compute_on_call=False) for key in list(classes)}\n",
    "\n",
    "        def update(self, key, value: Union[np.ndarray, List[np.ndarray]], n: int = 1):\n",
    "            \"\"\"\n",
    "            key: the class name to update embedding(s) or single value(s) for\n",
    "            value: embedding or any single value tensor\n",
    "            \"\"\"\n",
    "            if isinstance(value, np.ndarray) or not isinstance(value, Iterable):\n",
    "                self.monitor[key].update(value, n)\n",
    "            else:\n",
    "                for vec in value:\n",
    "                    self.monitor[key].update(vec, 1)\n",
    "            return self\n",
    "\n",
    "        def compute(self, key=None):\n",
    "            response = {}\n",
    "            if key is not None:\n",
    "                return self.monitor[key].compute()[0]\n",
    "            for key in self.monitor.keys():\n",
    "                response[key] = self.monitor[key].compute()[0]\n",
    "            return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    _docs,\n",
    "    _topic_per_doc,\n",
    "    _label_per_doc,\n",
    "    _topics_to_show=None,\n",
    "    _labels_to_show=None,\n",
    "    _reduced_embeddings=None,\n",
    "    sample: float = None,\n",
    "    hide_annotations: bool = False,\n",
    "    hide_document_hover: bool = False,\n",
    "    custom_labels: bool = False,\n",
    "    title: str = \"<b>Documents and Topics</b>\",\n",
    "    width: int = 1200,\n",
    "    height: int = 750) -> go.Figure:\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "            _topic_per_doc: Topic id assigned to each document.\n",
    "            _docs: The documents.\n",
    "            _topics_to_show: A selection of topics to visualize.\n",
    "                    Not to be confused with the topics that you get from `.fit_transform`.\n",
    "                    For example, if you want to visualize only topics 1 through 5:\n",
    "                    `topics = [1, 2, 3, 4, 5]`.\n",
    "            _reduced_embeddings: The 2D reduced embeddings of all documents in `_docs`.\n",
    "            sample: The percentage of documents in each topic that you would like to keep.\n",
    "                    Value can be between 0 and 1. Setting this value to, for example,\n",
    "                    0.1 (10% of documents in each topic) makes it easier to visualize\n",
    "                    millions of documents as a subset is chosen.\n",
    "            hide_annotations: Hide the names of the traces on top of each cluster.\n",
    "            hide_document_hover: Hide the content of the documents when hovering over\n",
    "                                specific points. Helps to speed up generation of visualization.\n",
    "            custom_labels: Whether to use custom topic labels that were defined using\n",
    "                       `topic_model.set_topic_labels`.\n",
    "            title: Title of the plot.\n",
    "            width: The width of the figure.\n",
    "            height: The height of the figure.\n",
    "    \"\"\"\n",
    "\n",
    "    if sample is None or sample > 1:\n",
    "        sample = 1\n",
    "\n",
    "    indices = []\n",
    "    for topic in set(_topic_per_doc):\n",
    "        s = np.where(np.array(_topic_per_doc) == topic)[0]  # Выбираем все индексы, соответствующие определенному топику\n",
    "        #\n",
    "        size = len(s) if len(s) < 100 else int(len(s) * sample)\n",
    "        indices.extend(np.random.choice(s, size=size, replace=False))\n",
    "\n",
    "    indices = np.array(indices)\n",
    "    # topic_per_doc[index] for index in indices\n",
    "    idf = pd.DataFrame(\n",
    "        {\n",
    "            \"topic\": [_topic_per_doc[idx] for idx in indices],\n",
    "            \"doc\": [_docs[idx] for idx in indices],\n",
    "            \"_label\": [_label_per_doc[idx] for idx in indices]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    monitor = Monitor(set(_label_per_doc))\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    if _reduced_embeddings is not None:\n",
    "        embeddings_2d = _reduced_embeddings[indices]\n",
    "\n",
    "        idf[\"x\"] = embeddings_2d[:, 0]\n",
    "        idf[\"y\"] = embeddings_2d[:, 1]\n",
    "\n",
    "    unique_topics = set(_topic_per_doc)\n",
    "    _topics_to_show = unique_topics if _topics_to_show is None else _topics_to_show\n",
    "\n",
    "    non_selected_topics = unique_topics.difference(_topics_to_show)\n",
    "\n",
    "    if len(non_selected_topics) == 0:\n",
    "        non_selected_topics = [-1]  # `bertopic` присваевает документам - `-1`, если он не относится ни к одному из кластеров\n",
    "\n",
    "    selection = idf.loc[idf.topic.isin(non_selected_topics), :]\n",
    "    selection[\"text\"] = \"\"\n",
    "    # selection.loc[len(selection), :] = [None, None, None, selection.x.mean(), selection.y.mean(), \"Other documents\"]\n",
    "    selection.loc[len(selection), :] = [None, None, \"\", selection.x.mean(), selection.y.mean(), \"Other documents\"]\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scattergl(\n",
    "            x=selection.x,\n",
    "            y=selection.y,\n",
    "            hovertext=selection.doc if not hide_document_hover else None,\n",
    "            hoverinfo=\"text\",\n",
    "            mode=\"markers+text\",\n",
    "            name=\"other\",\n",
    "            showlegend=False,\n",
    "            marker=dict(color=\"#CFD8DC\", size=5, opacity=0.5),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Теперь наносим каждый topic отдельно\n",
    "    # for label, topic in zip(range(len(unique_topics)), unique_topics):\n",
    "    for i, topic in enumerate(unique_topics):\n",
    "        if topic in _topics_to_show and topic != -1:\n",
    "            selection = idf.loc[idf.topic == topic, :]\n",
    "            selection[\"text\"] = \"\"\n",
    "\n",
    "            _selection = pl.from_pandas(selection)\n",
    "\n",
    "            # _selection.join(ldf, on=pl.col(\"topic\"))\n",
    "\n",
    "            _selection = _selection.with_row_count().\\\n",
    "                with_columns([\n",
    "                    pl.count().over(\"_label\").alias(\"label_len\")\n",
    "                ])\n",
    "\n",
    "            _selection_per_topk = _selection.sort(\"label_len\", descending=True).unique(subset=[\"label_len\"], maintain_order=True).top_k(3, by=\"label_len\")\n",
    "\n",
    "            _topk = _selection.join(_selection_per_topk, on=pl.col(\"row_nr\")).select(pl.col(\"_label\"), pl.col(\"label_len\")).to_arrow()\n",
    "\n",
    "            _label, _mass = [str(yi) for yi in _topk[\"_label\"]], [str(pi) for pi in _topk[\"label_len\"]]\n",
    "\n",
    "            for li, mi in zip(_label, _mass):\n",
    "                # score is a scale mi / len(_selection).\n",
    "                monitor.update(li, int(mi) * 1.0 / len(_selection))\n",
    "\n",
    "            _label_on_doc = \"  \".join([yi.strip()[:20] for yi, pi in zip(_label, _mass)]) # Будет показываться постоянно на облаке\n",
    "\n",
    "            _label_on_topic = \" \".join([yi.strip()[:22] + \" (\" + pi + \")\" for yi, pi in zip(_label, _mass)]) # Будет показываться справа по точке\n",
    "\n",
    "            # _label_doc = str(topic)\n",
    "            if not hide_annotations:\n",
    "                selection.loc[len(selection), :] = [None, None, \"\", selection.x.mean(), selection.y.mean(), _label_on_doc[:50]] # TODO: change topic to label\n",
    "                # selection.loc[len(selection), :] = [None, None, None, selection.x.mean(), selection.y.mean(), _label_doc] # TODO: change topic to label\n",
    "\n",
    "            fig.add_trace(\n",
    "                go.Scattergl(\n",
    "                    x=selection.x,\n",
    "                    y=selection.y,\n",
    "                    hovertext=selection.doc if not hide_document_hover else None,\n",
    "                    hoverinfo=\"text\",\n",
    "                    text=selection.text,\n",
    "                    mode=\"markers+text\",\n",
    "                    name=_label_on_topic,\n",
    "                    textfont=dict(size=12),\n",
    "                    marker=dict(size=5, opacity=0.5),\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Add grid in a 'plus' shape\n",
    "    x_range = (idf.x.min() - abs((idf.x.min()) * .15), idf.x.max() + abs((idf.x.max()) * .15))\n",
    "    y_range = (idf.y.min() - abs((idf.y.min()) * .15), idf.y.max() + abs((idf.y.max()) * .15))\n",
    "    fig.add_shape(type=\"line\",\n",
    "                  x0=sum(x_range) / 2, y0=y_range[0], x1=sum(x_range) / 2, y1=y_range[1],\n",
    "                  line=dict(color=\"#CFD8DC\", width=2))\n",
    "    fig.add_shape(type=\"line\",\n",
    "                  x0=x_range[0], y0=sum(y_range) / 2, x1=x_range[1], y1=sum(y_range) / 2,\n",
    "                  line=dict(color=\"#9E9E9E\", width=2))\n",
    "    fig.add_annotation(x=x_range[0], y=sum(y_range) / 2, text=\"D1\", showarrow=False, yshift=10)\n",
    "    fig.add_annotation(y=y_range[1], x=sum(x_range) / 2, text=\"D2\", showarrow=False, xshift=10)\n",
    "\n",
    "    # Stylize layout\n",
    "    fig.update_layout(\n",
    "        template=\"simple_white\",\n",
    "        title={\n",
    "            'text': f\"{title}\",\n",
    "            'x': 0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top',\n",
    "            'font': dict(\n",
    "                size=22,\n",
    "                color=\"Black\")\n",
    "        },\n",
    "        width=width,\n",
    "        height=height\n",
    "    )\n",
    "\n",
    "    fig.update_traces(textposition='top center')\n",
    "\n",
    "    fig.update_layout(\n",
    "        title_text='Распределение по топикам и TOP_3 соответствующих класса (по частоте) на каждый топик '\n",
    "    )\n",
    "    fig.update_layout(uniformtext_minsize=12, uniformtext_mode='hide')\n",
    "\n",
    "    fig.update_xaxes(visible=False)\n",
    "    fig.update_yaxes(visible=False)\n",
    "\n",
    "    \n",
    "\n",
    "    return fig, {k: v for k, v in monitor.compute().items() if v is not None and v is not np.nan}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silo(_df, col, labels):\n",
    "    pattern = \"|\".join(labels)\n",
    "    _df = _df.with_columns([pl.col(col).str.contains(pattern).alias(\"silo\")])\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf = Inferencer(\n",
    "            model='vdorogu/inferencer/models/web/labse_dense_retrieval_title.py',\n",
    "            storage_path=None,\n",
    "            model_data_path=str(Path(os.environ.get(\"MODEL\")).expanduser()),\n",
    "            batch_size=256,\n",
    "            mode='document_emb',\n",
    "            half=True,\n",
    "            gpus=0,\n",
    "            model_params={},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = M1Model(model=inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(str(Path(os.environ.get(\"DATASET\")).expanduser()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_model = UMAP(n_components=5, metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_model = KMeans(n_clusters=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Разметка данных слабо сепарабельна - настолько, что даже самому\n",
    "#       иногда сложно понять к какому из классов относится баннер\n",
    "# 2. Очень много классов, на которые приходится менее ста примеров\n",
    "\n",
    "# Поэтому, давайте сделаем небольшую предобработку,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape[0]) # всего примеров"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Сколько всего <b><u>уникальных</u></b> классов из разметки</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.select(\"taxons\").unique().shape[0]) # всего классов"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Кол-во классов среди которых мало примеров </p>\n",
    "\n",
    "$$p_i \\leq 100$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.with_columns([pl.count().over(pl.col(\"taxons\"))]).filter(pl.col(\"count\") < 100).shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Это очень много, поэтому просто удалить эти классы нельзя - пропадет много данных.</p>\n",
    "\n",
    "Давайте оставим только те $x_i$, где в названии класса есть популярный класс (т.к. разметка представляет структуру дерева)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = df.with_columns([pl.count().over(pl.col(\"taxons\"))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_pdf = _df.unique(subset=\"taxons\").sort(by=\"count\", descending=True).to_arrow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=[str(i) + \"|\" + str(x)[:10] for i, x in enumerate(_pdf[\"taxons\"])], y=[int(str(x)) for x in _pdf[\"count\"]]) # TODO: make unique\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"Распределение размеченных баннеров\", font=dict(size=12), automargin=True, yref='paper')\n",
    ")\n",
    "fig.update_layout(yaxis_title=None)\n",
    "fig.update_layout(xaxis_title=None)\n",
    "fig.update_xaxes(tickfont_size=14, ticks=\"outside\", ticklen=1, tickwidth=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.write_image(fig, file=\"original_label_mass.png\", scale=5, engine=\"kaleido\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Сначала фиксируем популярные классы, которые подходят для анализа</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [str(li) for li in _df.filter(pl.col(\"count\") >= 100).unique(\"taxons\").select(\"taxons\").to_arrow()[\"taxons\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df.pipe(partial(silo, col=\"taxons\", labels=labels)).filter(\"silo\") # Оставим те фразы, где есть такой \"топовый\" префикс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.shape # сильно лучше, хотя бы не половина :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs, labels = [str(x) for x in dff.to_arrow()[\"text\"]], [str(y) for y in dff.to_arrow()[\"taxons\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"EMBEDDINGS\" in os.environ.keys():\n",
    "    embeddings_path = Path(os.environ.get(\"EMBEDDINGS\")).expanduser()\n",
    "    if embeddings_path.exists():\n",
    "        embeddings = np.load(str(embeddings_path))\n",
    "    else:\n",
    "        embeddings = model.embed_documents(docs)\n",
    "        np.save(str(embeddings_path), embeddings)\n",
    "else:\n",
    "    embeddings = model.embed_documents(docs)\n",
    "\n",
    "assert embeddings.shape[0] == len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "botpic = BERTopic(umap_model=umap_model, hdbscan_model=KMeans(n_clusters=40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "botpic = botpic.fit(docs, embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, min_dist=0.0, metric=\"cosine\").fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# botpic.visualize_documents(docs, reduced_embeddings=reduced_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(docs))\n",
    "print(len(botpic.topics_))\n",
    "print(len(labels))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Теперь уже запускаем оценку, используя результаты кластеризации </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, monitor = evaluate(_docs=docs, _topic_per_doc=botpic.topics_, _label_per_doc=labels, _reduced_embeddings=reduced_embeddings, width=1920, height=1080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_html(\"report.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Посмотрим результаты оценки. Какие же классы плохо сепарабельны? </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_response = pl.from_dict({\"x\": monitor.keys(), \"y\": monitor.values()}).to_arrow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(x=[str(i) + \"|\" + str(x)[:22] for i, x in enumerate(_response[\"x\"])], y=[float(str(x)) for x in _response[\"y\"]]) # TODO: make unique\n",
    "fig.update_layout(\n",
    "    title=dict(text=\"Сепарабельность фраз по кластеризации\", font=dict(size=12), automargin=True, yref='paper')\n",
    ")\n",
    "fig.update_layout(yaxis_title=None)\n",
    "fig.update_layout(xaxis_title=None)\n",
    "fig.update_xaxes(tickfont_size=14, ticks=\"outside\", ticklen=1, tickwidth=1)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.write_image(fig, file=\"metrica_per_topic.png\", scale=5, engine=\"kaleido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jarvis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
